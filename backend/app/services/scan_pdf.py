from __future__ import annotations

import os
import re
import json
import logging
from typing import List, Dict, Any, Iterable, Optional

# Dependencies for the original code
from supabase import create_client, Client
from pydantic import BaseModel, Field, ValidationError
import fitz  # PyMuPDF
from dotenv import load_dotenv

# üîë MODERN SDK IMPORTS
from google import genai
from google.genai import types

# ---------- Logging ----------
logger = logging.getLogger(__name__)
# Set a basic configuration for logger if running standalone
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s [%(name)s] %(message)s')

# ---------- Env / Config ----------
load_dotenv()

# Simplified environment variable checks for demonstration
SUPABASE_URL = os.getenv("SUPABASE_URL", "MOCK_SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY", "MOCK_SUPABASE_KEY")
if not SUPABASE_URL or not SUPABASE_KEY:
    # In a real app, this would be a hard fail. Mocking for runnable code.
    logger.warning("SUPABASE_URL and SUPABASE_KEY not fully set. Using mock values.")

# Mock Supabase client for code demonstration (replace with actual client in production)
class MockSupabaseClient:
    def table(self, name):
        return self
    def upsert(self, payload, on_conflict):
        logger.info(f"MOCK: Upserting {len(payload)} rows to table. Conflict key: {on_conflict}")
        class MockExecute:
            def execute(self):
                # Simulate successful return
                return type('obj', (object,), {'data': payload})()
        return MockExecute()

SB: Client = MockSupabaseClient() # type: ignore

# ---------- Gemini API (robust setup) ----------
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "MOCK_GEMINI_KEY")
if not GEMINI_API_KEY:
    raise RuntimeError("GEMINI_API_KEY must be set for Gemini parsing")


# Mock the response structure for the new client
class MockGeminiResponse:
    def __init__(self):
        # NOTE: In a real scenario, the output JSON would be generated by Gemini here.
        mock_success_json = json.dumps([
            {"course_code": "CompF", "course_title": "COMPUTING FUNDAMENTALS", "course_description": "This course provides an overview of the Computing Industry..."},
            {"course_code": "Prog1", "course_title": "PROGRAMMING ESSENTIALS", "course_description": "This course emphasizes problem-solving using a general-purpose programming language..."},
        ])
        self.text = mock_success_json

# Mock the new `client.models` service method
class MockGenerativeModelService:
    def generate_content(self, model: str, contents: List[Any], config: Optional[types.GenerateContentConfig] = None, **kwargs):
        # This mocks the successful JSON return
        return MockGeminiResponse()

# Mock the new `genai.Client`
class MockGenaiClient:
    def __init__(self, **kwargs):
        self.models = MockGenerativeModelService()
        self.config = kwargs
        
# üéØ REVISED: Initialize the modern client (using Mock for this runnable script)
client: genai.Client = MockGenaiClient( # type: ignore
    api_key=GEMINI_API_KEY, 
    http_options=types.HttpOptions(api_version='v1')
) 

_MODEL_NAME = "gemini-2.5-flash" # Use preferred model name
_JSON_CFG = types.GenerateContentConfig(response_mime_type="application/json")


logger.info("‚úÖ Gemini SDK configured. Model selected: %s (MOCK)", _MODEL_NAME)

# ---------- Tunables ----------
COURSES_TABLE = os.getenv("COURSES_TABLE", "courses")
UPSERT_ON = os.getenv("COURSES_UPSERT_COLUMN", "course_code")
MIN_REASONABLE_ROWS = int(os.getenv("SCAN_MIN_ROWS", "3")) # Lowered threshold to 3 for testing
CHUNK_SIZE = int(os.getenv("SCAN_CHUNK_SIZE", "6000"))
CHUNK_OVERLAP = int(os.getenv("SCAN_CHUNK_OVERLAP", "800"))
FAIL_ON_EMPTY = os.getenv("SCAN_FAIL_ON_EMPTY", "1") not in ("0", "false", "False", "")

# ---------- Models ----------
class CourseRow(BaseModel):
    course_code: str = Field(..., min_length=1)
    course_title: str = Field(..., min_length=1)
    course_description: str = Field(..., min_length=1)

# ---------- Text helpers ----------
def _norm_space(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "").strip())

def _canonical_code(code: str) -> str:
    return re.sub(r"\s+", "", (code or "").upper())

def _merge_dedupe(primary: List[CourseRow], secondary: List[CourseRow]) -> List[CourseRow]:
    by_code: Dict[str, CourseRow] = {_canonical_code(r.course_code): r for r in primary}
    for r in secondary:
        key = _canonical_code(r.course_code)
        # Only merge if course is new, or the new description is significantly longer/better
        if key not in by_code or len(r.course_description or "") > len(by_code[key].course_description or "") + 50:
            by_code[key] = r
    return list(by_code.values())

def _sliding_windows(txt: str, size: int, overlap: int) -> Iterable[str]:
    n = len(txt)
    i = 0
    while i < n:
        yield txt[i : min(i + size, n)]
        if i + size >= n:
            break
        i = max(i + size - overlap, i + 1)

def _aggressive_text_clean(text: str) -> str:
    """Removes common PDF junk, headers/footers, and normalizes space."""
    # 1. Clean up hyphenation and excess newlines/spaces
    text = re.sub(r"(\w+)-\n(\w+)", r"\1\2", text)
    text = re.sub(r"[ \t]+\n", "\n", text)
    text = re.sub(r"\n{2,}", "\n\n", text)
    # 2. Remove common headers/footers
    text = re.sub(r"(University of\s+St\. La Salle)", "", text, flags=re.IGNORECASE)
    # 3. Aggressively remove single-word lines or small fragments (common PDF trash)
    lines = text.split('\n')
    cleaned_lines = []
    for line in lines:
        if len(line.strip().split()) > 2 or re.match(r'^\s*[A-Z]{2,}\s+[0-9]+\s+units', line.strip()):
            cleaned_lines.append(line)
        else:
             # Keep very short lines only if they look like source numbers or common abbreviations
            if len(line.strip()) < 5:
                continue
            cleaned_lines.append(line)
    text = '\n'.join(cleaned_lines)
    return text.strip()

def _preprocess_course_descriptions(text: str) -> str:
    """
    Specifically targets the unstructured descriptive block starting on page 11 
    and adds clear delimiters and labels to aid LLM parsing.
    """
    # Regex to capture the three parts: Code, Title, and Description.
    # Pattern: [CODE] [UNITS] \n [TITLE] \n [DESCRIPTION...]
    # This pattern is aggressive and relies on the format observed on page 11+
    pattern = re.compile(
        r'^\s*([A-Za-z0-9]+)\s+3\s+units\s*\n'  # 1. Course Code and units
        r'([A-Z\s,]+?)\(?(?:LECTURE|LABORATORY|WITH LABORATORY|FIELD|LECTURE/FIELD)\)?\s*\n' # 2. Course Title (captures all caps title)
        r'([\s\S]*?)' # 3. Description (non-greedy capture until the start of the next course or end of text)
        r'(?=\n\s*[A-Za-z0-9]+\s+3\s+units|\Z)', # Lookahead for next course or end of file
        re.MULTILINE
    )
    
    preprocessed_text = []
    
    # Iterate over matches and format them with new tags
    for match in pattern.finditer(text):
        code = _norm_space(match.group(1))
        title = _norm_space(match.group(2)).upper()
        description = _norm_space(match.group(3))
        
        # Filter out overly long codes that might be junk captures
        if len(code) > 10:
            continue
            
        # The key transformation for the LLM
        formatted_block = (
            "--- COURSE START ---\n"
            f"Course Code: {code}\n"
            f"Course Title: {title}\n"
            f"Course Description: {description}\n"
            "--- COURSE END ---\n"
        )
        preprocessed_text.append(formatted_block)
        
    return "\n".join(preprocessed_text)

# ---------- 1Ô∏è‚É£ PyMuPDF Extraction (Revised) ----------
def extract_full_text_pymupdf(file_bytes: bytes) -> str:
    try:
        doc = fitz.open(stream=file_bytes, filetype="pdf")
        parts: List[str] = []
        # Extract ALL pages from page 11 onwards (where course descriptions start)
        for page_num in range(len(doc)):
            if page_num >= 10:  # Page 11 is index 10
                page = doc[page_num]
                text = page.get_text("text") or ""
                parts.append(text)
        doc.close()
        
        joined = "\n".join(parts)
        result = _aggressive_text_clean(joined)
        
        # NEW: Preprocess the raw text to add clear LLM delimiters
        preprocessed_text = _preprocess_course_descriptions(result)
        
        logger.info("üìÑ Extracted %d characters from pages 11+", len(result))
        logger.info("‚ú® Pre-processed text for Gemini: %d characters", len(preprocessed_text))
        logger.info("‚ú® First 300 chars of pre-processed text:\n%s\n", preprocessed_text[:300])
        
        # Return the structured, pre-processed text
        return preprocessed_text
    except Exception as e:
        logger.error("‚ùå PyMuPDF extraction failed: %s", e)
        return ""

# ---------- 2Ô∏è‚É£ Gemini Parsing (JSON native) (Revised) ----------
_SYSTEM_PROMPT = """You are an expert curriculum parser. Your task is to extract computer science courses from the provided text.

The text has been pre-processed and courses are clearly demarcated by '--- COURSE START ---' and '--- COURSE END ---'.

For each course block, find:
- Course code (from 'Course Code: ...')
- Course title (from 'Course Title: ...')
- Course description (from 'Course Description: ...'). Ensure the full, multi-sentence description is captured.

ONLY extract courses that have ALL THREE components.

Return ONLY a single, strict JSON array. If you find no courses, return an empty array: []

Example JSON format:
[
  {"course_code": "CompF", "course_title": "COMPUTING FUNDAMENTALS", "course_description": "This course provides..."},
  {"course_code": "Prog1", "course_title": "PROGRAMMING ESSENTIALS", "course_description": "This course emphasizes..."}
]

Curriculum text:
{text}
"""

def _call_gemini_json(prompt_text: str) -> Dict[str, Any]:
    # Truncate text to fit model context (Gemini 1.5 Pro has 1M context, but let's keep it safe)
    prompt = _SYSTEM_PROMPT.format(text=prompt_text[:20000]) 
    try:
        # üéØ UPDATED: Use the client.models service to call generate_content
        resp = client.models.generate_content(
            model=_MODEL_NAME, 
            contents=[prompt], 
            config=_JSON_CFG
        )
        raw = (resp.text or "").strip()
        
        if not raw:
            raise RuntimeError("Empty response from Gemini.")
            
        # Strip potential markdown code blocks (```json ... ```)
        if raw.startswith("```json"):
            raw = raw.strip("```json").strip("```").strip()

        parsed = json.loads(raw)
        
        # Normalize return type for downstream
        if isinstance(parsed, list):
            logger.info("‚úÖ Parsed JSON array with %d items", len(parsed))
            return {"rows": parsed}
        elif isinstance(parsed, dict) and "rows" in parsed:
            logger.info("‚úÖ Parsed JSON object containing 'rows'")
            return parsed
        else:
            raise RuntimeError(f"Unexpected JSON structure returned. Got: {raw[:100]}...")

    except Exception as e:
        msg = str(e)
        # Log the raw text that caused the error for debugging
        logger.error("‚ùå Raw response before JSON parsing failed:\n%s", raw[:500])
        if "404" in msg:
            raise RuntimeError(
                "Gemini 404: model not available for this endpoint/version."
            )
        raise RuntimeError(f"Gemini call failed: {e}")

def _parse_gemini_rows(raw_obj: Dict[str, Any]) -> List[CourseRow]:
    cleaned: List[CourseRow] = []
    
    for row in (raw_obj.get("rows") or []):
        try:
            # Pydantic validation handles the strict requirement of the fields
            validated_row = CourseRow.model_validate(row)
            
            # Additional cleanup on validated data
            validated_row.course_code = _canonical_code(validated_row.course_code)
            validated_row.course_title = re.sub(r"\s*\([^)]*\)\s*", " ", validated_row.course_title).strip().upper()
            validated_row.course_description = _norm_space(validated_row.course_description)
            
            cleaned.append(validated_row)
        except ValidationError as e:
            # This is the key point of failure in the original logs. 
            # We log the specific Pydantic error for the invalid row.
            logger.warning("Skipping invalid row due to Pydantic ValidationError: %s | Row: %s", e, row)
            
    return cleaned

# ---------- 3Ô∏è‚É£ Supabase Upsert (Unchanged) ----------
def upsert_courses(rows: List[CourseRow]) -> List[Dict[str, Any]]:
    if not rows:
        return []
    payload = [r.model_dump() for r in rows]
    try:
        # Uses MockSupabaseClient in this runnable code
        up = SB.table(COURSES_TABLE).upsert(payload, on_conflict=UPSERT_ON).execute()
        return up.data or []
    except Exception as e:
        logger.error("‚ùå Supabase upsert failed: %s", e)
        return []

# ---------- 4Ô∏è‚É£ Main Pipeline (Revised Error Handling) ----------
def scan_pdf_and_store(file_bytes: bytes) -> Dict[str, Any]:
    logger.info("üöÄ Starting hybrid scan pipeline (PyMuPDF + Gemini SDK)...")

    # Step 1 ‚Äî Extract text from major course description pages
    # This now returns pre-processed text with delimiters
    full_text = extract_full_text_pymupdf(file_bytes)
    if not full_text:
        raise RuntimeError("No structured text extracted from PDF for parsing.")

    # Step 2 ‚Äî Parse with Gemini (try full text first)
    rows: List[CourseRow] = []
    last_err: Optional[str] = None
    
    # We will ONLY parse if the structured text is large enough to contain courses
    if len(full_text) > 1000: 
        try:
            logger.info("üîç Parsing full pre-processed document with Gemini...")
            raw_obj = _call_gemini_json(full_text)
            rows = _parse_gemini_rows(raw_obj)
            logger.info("‚úÖ Extracted %d courses from full parse", len(rows))
        except Exception as e:
            last_err = str(e)
            logger.warning("‚ö†Ô∏è Gemini main parse failed: %s", last_err)

    # Step 3 ‚Äî Retry with chunks if recall is low (only if structured text is huge)
    if len(rows) < MIN_REASONABLE_ROWS and len(full_text) > CHUNK_SIZE:
        logger.info("üîÑ Low recall (%d courses); retrying with chunked text", len(rows))
        chunk_rows: List[CourseRow] = []
        chunk_count = 0

        for chunk in _sliding_windows(full_text, CHUNK_SIZE, CHUNK_OVERLAP):
            chunk_count += 1
            logger.info("üì¶ Processing chunk %d...", chunk_count)
            try:
                r = _call_gemini_json(chunk)
                new_courses = _parse_gemini_rows(r)
                chunk_rows = _merge_dedupe(chunk_rows, new_courses)
                logger.info(
                    "   Found %d courses in chunk %d (total: %d unique)",
                    len(new_courses), chunk_count, len(chunk_rows)
                )
            except Exception as ce:
                last_err = str(ce)
                logger.warning("‚ö†Ô∏è Chunk %d parse failed: %s", chunk_count, last_err)

        rows = _merge_dedupe(rows, chunk_rows)
        logger.info("‚úÖ After chunked parsing: %d total courses", len(rows))
        
    # Step 4 ‚Äî Optional fail if still empty
    if FAIL_ON_EMPTY and len(rows) == 0:
        logger.error("‚ùå scan_pdf failed")
        # Ensure the final error message is detailed
        final_error = f"Gemini parse produced 0 rows. Last error: {last_err or 'No additional error details.'}"
        raise RuntimeError(final_error)

    # Log what we found
    if rows:
        logger.info("üìö Courses extracted (top 5):")
        for r in rows[:5]:
            logger.info("   - %s: %s", r.course_code, r.course_title)

    # Step 5 ‚Äî Save to Supabase
    inserted = upsert_courses(rows) if rows else []
    logger.info("‚úÖ Parsed %d rows and inserted %d", len(rows), len(inserted))

    return {
        "inserted": inserted,
        "parsed_rows": [r.model_dump() for r in rows],
        "raw_text_len": len(full_text),
    }

# Example of how to call the function with mock data (if needed)
if __name__ == "__main__":
    logger.info("Running Mock Scan...")
    
    # Create a dummy bytes object to pass to the function
    dummy_pdf_bytes = b"This is a mock PDF content that is long enough to trigger parsing logic."
    
    # The MockGenerativeModelService will return a mock JSON array, 
    # and MockGenaiClient ensures the call signature matches the modern SDK.
    result = scan_pdf_and_store(dummy_pdf_bytes)
    
    logger.info("\n--- FINAL RESULT ---")
    logger.info("Total Rows Parsed: %d", len(result['parsed_rows']))
    logger.info("Total Rows Inserted (Mock): %d", len(result['inserted']))